{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSOY2hKYHHDH",
    "outputId": "e9f56ca9-2077-41e1-9736-d3db86d74f0a"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "[ ! -d \"/content/code-t5\" ] && git clone 'https://github.com/bzz/code-t5.git'\n",
    "cd code-t5/\n",
    "git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXkBeXzCFt35",
    "outputId": "91d4bc33-b004-43b6-c7a1-27fff4fac030"
   },
   "outputs": [],
   "source": [
    "print(\"Installing dependencies...\")\n",
    "%tensorflow_version 2.x\n",
    "!pip install -qr code-t5/requirements-train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NknEpagWWVP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = \"gs://t5-codex\" #@param { type: \"string\" }\n",
    "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
    "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "MODEL_SIZE = \"large\" #@param[\"small\", \"base\", \"large\", \"3B\", \"11B\"]\n",
    "MODEL_DIR = os.path.join(MODELS_DIR, MODEL_SIZE)\n",
    "\n",
    "ON_CLOUD = True\n",
    "\n",
    "TRAIN_STEPS = 30000 #@param {type: \"integer\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0APdooM8Jy63",
    "outputId": "cfaa326e-e7f5-4687-8524-73441d7b674b"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import t5\n",
    "import t5.models\n",
    "import seqio\n",
    "\n",
    "\n",
    "if ON_CLOUD:\n",
    "  print(\"Setting up GCS access...\")\n",
    "  import tensorflow_gcs_config\n",
    "  from google.colab import auth\n",
    "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
    "  TPU_TOPOLOGY = \"v2-8\"\n",
    "  try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    TPU_ADDRESS = tpu.get_master()\n",
    "    print('Running on TPU:', TPU_ADDRESS)\n",
    "  except ValueError:\n",
    "    raise BaseException('ERROR: Not connected to a TPU runtime')\n",
    "  auth.authenticate_user()\n",
    "  tf.enable_eager_execution()\n",
    "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
    "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
    "\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Improve logging.\n",
    "from contextlib import contextmanager\n",
    "import logging as py_logging\n",
    "\n",
    "if ON_CLOUD:\n",
    "  tf.get_logger().propagate = False\n",
    "  py_logging.root.setLevel('INFO')\n",
    "\n",
    "@contextmanager\n",
    "def tf_verbosity_level(level):\n",
    "  log_level = tf.logging.get_verbosity()\n",
    "  tf.logging.set_verbosity(level)\n",
    "  yield\n",
    "  tf.logging.set_verbosity(log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gS143v6OHNT0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ez0ujjN5RyI-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/content/code-t5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIfttcBXyQHJ",
    "outputId": "5d4e873a-e561-44db-a018-eedbee100e46"
   },
   "outputs": [],
   "source": [
    "seqio.TaskRegistry.names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMNSNfToHlYn",
    "outputId": "d521397d-6988-4754-89d1-bb4c7dcf37d0"
   },
   "outputs": [],
   "source": [
    "import codeT5.tasks\n",
    "\n",
    "py5k_lm = seqio.TaskRegistry.get(\"py_50stars_2019\")\n",
    "ds = py5k_lm.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 32})\n",
    "print(\"A few preprocessed validation examples...\")\n",
    "for ex in tfds.as_numpy(ds.take(5)):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2nKb9i6HuyH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfyI4rw8bGU9"
   },
   "outputs": [],
   "source": [
    "# Public GCS path for T5 pre-trained model checkpoints\n",
    "BASE_PRETRAINED_DIR = \"gs://t5-data/pretrained_models\"\n",
    "PRETRAINED_DIR = os.path.join(BASE_PRETRAINED_DIR, MODEL_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHO5xURSHugU"
   },
   "outputs": [],
   "source": [
    "gin_file=[\"models/shared-prefix_lm.gin\"]\n",
    "gin_param=None\n",
    "\n",
    "if ON_CLOUD and MODEL_SIZE == \"3B\":\n",
    "  tf.logging.warning(\n",
    "      \"The `3B` model is too large to use with the 5GB GCS free tier. \"\n",
    "      \"Make sure you have at least 25GB on GCS before continuing.\"\n",
    "  )\n",
    "elif ON_CLOUD and MODEL_SIZE == \"11B\":\n",
    "  raise ValueError(\n",
    "      \"The `11B` parameter is too large to fine-tune on the `v2-8` TPU \"\n",
    "      \"provided by Colab. Please comment out this Error if you're running \"\n",
    "      \"on a larger TPU.\"\n",
    "  )\n",
    "\n",
    "# Set parallelism and batch size to fit on v2-8 TPU (if possible).\n",
    "# Limit number of checkpoints to fit within 5GB (if possible).\n",
    "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
    "    \"small\": (1, 256, 16),\n",
    "    \"base\": (2, 128, 8),\n",
    "    \"large\": (8, 64, 4),\n",
    "    \"3B\": (8, 16, 1),\n",
    "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
    "\n",
    "import importlib\n",
    "importlib.import_module('codeT5')\n",
    "\n",
    "import gin\n",
    "import pkg_resources\n",
    "from t5.models import mesh_transformer\n",
    "\n",
    "\n",
    "gin.add_config_file_search_path(\n",
    "    pkg_resources.resource_filename(\"codeT5\", \"gin\"))\n",
    "\n",
    "skip_unknown=mesh_transformer.DEPRECATED_GIN_REFERENCES\n",
    "gin.parse_config_files_and_bindings(\n",
    "    gin_file, gin_param,\n",
    "    skip_unknown=skip_unknown\n",
    ")\n",
    "  \n",
    "# We must overide this binding explicitly since it is set to a deprecated\n",
    "# function or class in many existing configs.\n",
    "gin.bind_parameter(\"run.vocabulary\", mesh_transformer.get_vocabulary())\n",
    "gin.finalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zDZMglMWdFX"
   },
   "outputs": [],
   "source": [
    "tf.io.gfile.makedirs(MODEL_DIR)\n",
    "# The models from our paper are based on the Mesh Tensorflow Transformer.\n",
    "model = t5.models.MtfModel(\n",
    "    model_dir=MODEL_DIR,\n",
    "    tpu=TPU_ADDRESS,\n",
    "    tpu_topology=TPU_TOPOLOGY,\n",
    "    model_parallelism=model_parallelism,\n",
    "    batch_size=train_batch_size,\n",
    "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
    "    learning_rate_schedule=0.003,\n",
    "    save_checkpoints_steps=5000,\n",
    "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
    "    iterations_per_loop=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrUGGGwKmHoR",
    "outputId": "d86bee98-d619-4a36-9bf4-c4c5b7078ca6"
   },
   "outputs": [],
   "source": [
    "pip install -U tensorboard-plugin-profile \"cloud-tpu-profiler>=2.3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-OvTSlgJgxf"
   },
   "outputs": [],
   "source": [
    "if ON_CLOUD:\n",
    "  %reload_ext tensorboard\n",
    "%tensorboard --logdir=\"$MODEL_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YQ2XYy3dWm_"
   },
   "outputs": [],
   "source": [
    "!kill 924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YRNVZBNW9v5"
   },
   "outputs": [],
   "source": [
    "10.126.165.74:8466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d6RTzGbW9b7"
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    mixture_or_task_name=\"py5k_prefix_lm\",\n",
    "    steps=TRAIN_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjaQK6x9aZmY",
    "outputId": "e4b874ce-9dbc-4685-d040-bb2a06e09c14"
   },
   "outputs": [],
   "source": [
    " !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miNB933xYklP"
   },
   "source": [
    "# Cache\n",
    "\n",
    "Cache dataset (depends on Apache Beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEkBh0_JiIx3"
   },
   "outputs": [],
   "source": [
    "!pip install apache-beam[gcp] python-snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yALEltupYj_F",
    "outputId": "11125e35-a927-4bb3-de9f-399b9972b796"
   },
   "outputs": [],
   "source": [
    "# works only with TextLineDataSource\n",
    "!cd code-t5 && python -m seqio.scripts.cache_tasks_main \\\n",
    " --tasks=py_50stars_top5k_2019 \\\n",
    " --module_import=codeT5.tasks \\\n",
    " --output_cache_dir='gs://t5-codex/cache' \\\n",
    " --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elAMBGl9nbIq"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC-y4mZj8t10"
   },
   "source": [
    "## Uncached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boV6png_Y4yz",
    "outputId": "c97ae04c-59eb-494c-9b92-2a84fdf4c46b"
   },
   "outputs": [],
   "source": [
    "# no cache, v2-8, model_parallelism = 2\n",
    "!echo \"$TPU_TOPOLOGY\"\n",
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.model_parallelism = 2\" \\\n",
    "  --batch_size=128 \\ # default tokens_per_replica=2048, 2048*8/512 = 32 seq/batch is overriden by tokens_per_batch = 65556\n",
    "  --gin_param=\"run.train_steps = $TRAIN_STEPS\" \\\n",
    "  --gin_param=\"run.keep_checkpoint_max = 8\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py5k_prefix_lm'\"\n",
    "\n",
    "# models/shared-prefix_lm.gin\n",
    "#  --gcp_project=\"${PROJECT}\" \\\n",
    "#  --tpu_zone=\"${ZONE}\" \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "swi5cghoWmFV",
    "outputId": "0b31c1c4-8285-4961-de08-7fb6637c3010"
   },
   "outputs": [],
   "source": [
    "# no cache, v2-8, model_parallelism = 1\n",
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.model_parallelism = 1\" \\\n",
    "  --gin_param=\"run.train_steps = 16000\" \\\n",
    "  --gin_param=\"run.keep_checkpoint_max = 8\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py5k_prefix_lm'\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P7kOZVY8jNN"
   },
   "source": [
    "## Cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PflVuKGTHz1r"
   },
   "source": [
    "### Base\n",
    "\n",
    "Train 2xBERT-base 220M param model (Total size: 138M) on top5k repos with >50 stars dataset (~400M tokes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHr-mCHQahRe",
    "outputId": "06f39d38-b785-402d-e955-702d8835e300"
   },
   "outputs": [],
   "source": [
    "#cache, v2-8, model_parallelism = 1\n",
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --additional_task_cache_dirs='$BASE_DIR/cache' \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.model_parallelism = 1\" \\\n",
    "  --gin_param=\"run.train_steps = $TRAIN_STEPS\" \\\n",
    "  --gin_param=\"run.keep_checkpoint_max = 8\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py_50stars_top5k_2019'\" \\\n",
    "  --gin_param=\"mesh_train_dataset_fn.use_cached = True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-jc1_K81Iua",
    "outputId": "f77201b1-2eaa-4528-e9dc-69da77a7c08a"
   },
   "outputs": [],
   "source": [
    "# cache, v2-8, model_parallelism = 2\n",
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --additional_task_cache_dirs='$BASE_DIR/cache' \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.model_parallelism = 2\" \\\n",
    "  --gin_param=\"run.train_steps = $TRAIN_STEPS\" \\\n",
    "  --gin_param=\"run.keep_checkpoint_max = 8\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py_50stars_top5k_2019'\" \\\n",
    "  --gin_param=\"mesh_train_dataset_fn.use_cached = True\"\n",
    "\n",
    "# utils.run batch_size = tokens_per_replica=2048, 2048*8/512 = 32 seq/batch, wich is overriden by tokens_per_batch = 65556\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elwEukjXis2x"
   },
   "source": [
    "10.4.42.106:8466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gLkagXkEml9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPpOJrSHH3gj"
   },
   "source": [
    "### Large\n",
    "\n",
    "Train a larger model, 2xBERT-large 770M param (Total size: 436M), on bigger dataset (2.1B tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxNu4BEiH5AQ",
    "outputId": "0068bcaa-7794-48d1-e685-f769140cd9bb"
   },
   "outputs": [],
   "source": [
    "# cache, v2-8, model_parallelism = 2\n",
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --additional_task_cache_dirs='$BASE_DIR/cache' \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_file=\"models/bi_bert_large.gin\" \\\n",
    "  --gin_param=\"run.train_steps = $TRAIN_STEPS\" \\\n",
    "  --gin_param=\"run.keep_checkpoint_max = 8\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py_50stars_2019'\" \\\n",
    "  --gin_param=\"mesh_train_dataset_fn.use_cached = True\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwrwsxirnW26"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7kdMBgDxwX7",
    "outputId": "d6225b9e-dc76-4f52-b4d2-5405c74d812d"
   },
   "outputs": [],
   "source": [
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_file=\"eval.gin\" \\\n",
    "  --gin_file=\"beam_search.gin\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"split = 'validation'\" \\\n",
    "  --gin_param=\"eval_checkpoint_step = -1\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py5k_prefix_lm'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsFVyJUJxw23",
    "outputId": "4e1e46fd-9f8f-4564-c705-a3dedf9e2ff0"
   },
   "outputs": [],
   "source": [
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main  \\\n",
    "  --tpu=\"$TPU_ADDRESS\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --t5_tfds_data_dir=\"$DATA_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --gin_location_prefix=\"codeT5/gin/\" \\\n",
    "  --gin_file=\"models/shared-prefix_lm.gin\" \\\n",
    "  --gin_file=\"models/bi_bert_large.gin\" \\\n",
    "  --gin_file=\"perplexity_eval.gin\" \\\n",
    "  --gin_file=\"beam_search.gin\" \\\n",
    "  --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '$TPU_TOPOLOGY'\" \\\n",
    "  --gin_param=\"split = 'validation'\" \\\n",
    "  --gin_param=\"eval_checkpoint_step = -1\" \\\n",
    "  --gin_param=\"MIXTURE_NAME = 'py_50stars_2019'\" \\\n",
    "  --additional_task_cache_dirs='$BASE_DIR/cache' \\\n",
    "  --gin_param=\"mesh_eval_dataset_fn.use_cached = True\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RnH2fA9HC5n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyNvItRKa9Zn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oMk-CFBa99A"
   },
   "source": [
    "# Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4U4VKj9xjrU"
   },
   "outputs": [],
   "source": [
    "PROJECT=\"data-analytics-experiments\"\n",
    "ZONE=\"europe-west4a\"\n",
    "EXPORT_DIR=os.path.join(MODEL_DIR, \"export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKi-R9Tea_iV",
    "outputId": "b641720c-a77f-4c8c-d1f8-5d2d164fd865"
   },
   "outputs": [],
   "source": [
    "!cd code-t5/ && python -m t5.models.mesh_transformer_main \\\n",
    "  --gcp_project=\"$PROJECT\" \\\n",
    "  --tpu_zone=\"$ZONE\" \\\n",
    "  --model_dir=\"$MODEL_DIR\" \\\n",
    "  --module_import=\"codeT5.tasks\" \\\n",
    "  --use_model_api \\\n",
    "  --mode=\"export_predict\" \\\n",
    "  --export_dir=\"$EXPORT_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICIm0YlCEnjY"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_nmv2TyWEKF"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "!pip install tensorflow-text\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "somEKQ4EbULb",
    "outputId": "1d7a0ded-ff22-4009-e12f-0be40c5ad6e8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text  # Required to run exported model.\n",
    "\n",
    "saved_model_path = os.path.join(EXPORT_DIR, max(tf.io.gfile.listdir(EXPORT_DIR)))\n",
    "\n",
    "def load_predict_fn(model_path):\n",
    "  if tf.executing_eagerly():\n",
    "    print(\"Loading SavedModel in eager mode.\")\n",
    "    imported = tf.saved_model.load(model_path, [\"serve\"])\n",
    "    return lambda x: imported.signatures['serving_default'](tf.constant(x))['outputs'].numpy()\n",
    "  else:\n",
    "    print(\"Loading SavedModel in tf 1.x graph mode.\")\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    sess = tf.compat.v1.Session()\n",
    "    meta_graph_def = tf.compat.v1.saved_model.load(sess, [\"serve\"], model_path)\n",
    "    signature_def = meta_graph_def.signature_def[\"serving_default\"]\n",
    "    print(\"Input name: \" + str(signature_def.inputs))\n",
    "    return lambda x: sess.run(\n",
    "        fetches=signature_def.outputs[\"outputs\"].name, \n",
    "        feed_dict={signature_def.inputs[\"inputs\"].name: x}\n",
    "    )\n",
    "\n",
    "predict_fn = load_predict_fn(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJO-FOIhbVRP",
    "outputId": "07cd9422-a6c4-4244-9edb-f88609a4d6f6"
   },
   "outputs": [],
   "source": [
    "def answer(question):\n",
    "  return predict_fn([question])[0].decode('utf-8')\n",
    "\n",
    "for question in [\"password = \",\n",
    "                  \"def __main__():ÄŠ  \",\n",
    "                  \"import\",\n",
    "                  \"a\"]:\n",
    "    print(answer(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKfGbwBKU7I-",
    "outputId": "82b8d823-9cf6-4220-a3a4-f5c85ef0f51c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIM1m2YUXJDt",
    "outputId": "c5c5bd20-de85-48da-8b49-b7e354a566a8"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ-TZ0gJbcSv"
   },
   "source": [
    "# Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "He69rzZNbe2B"
   },
   "outputs": [],
   "source": [
    "export MODEL_NAME=\"py5k_prefix_lm\"\n",
    "export SAVED_MODEL_PATH=\"${PWD}/mtf-model-export\"\n",
    "\n",
    "sudo systemctl start docker\n",
    "\n",
    "gsutil cp 'gs://t5-codex/models/large/export/1630574205' $SAVED_MODEL_PATH\n",
    "\n",
    "# Download the TensorFlow Serving Docker image and repo:\n",
    "docker pull tensorflow/serving:nightly\n",
    "\n",
    "# First, run a serving image as a daemon:\n",
    "docker run -d --name serving_base tensorflow/serving:nightly\n",
    "\n",
    "# Next, copy the `SavedModel` to the container's model folder:\n",
    "docker cp $SAVED_MODEL_PATH serving_base:/models/$MODEL_NAME\n",
    "\n",
    "# Now, commit the container that's serving the model:\n",
    "docker commit --change \"ENV MODEL_NAME $MODEL_NAME\" serving_base $MODEL_NAME\n",
    "\n",
    "# Finally, save the image to a tar file:\n",
    "docker save $MODEL_NAME -o $MODEL_NAME.tar\n",
    "\n",
    "# stop `serving_base`:\n",
    "docker kill serving_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ys2yGSkgbicM"
   },
   "outputs": [],
   "source": [
    "docker run -t --rm -p 8501:8501 --name \"$MODEL_NAME-server\" $MODEL_NAME &\n",
    "\n",
    "curl -d '{\"inputs\": [\"import tensorflow \"]}' \\\n",
    "    -X POST \"http://localhost:8501/v1/models/$MODEL_NAME:predict\"\n",
    "\n",
    "docker stop \"$MODEL_NAME-server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-4tcUT7nNMV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iOHNojcemOC"
   },
   "outputs": [],
   "source": [
    "# 18.04 LTS https://docs.docker.com/engine/install/ubuntu/\n",
    "\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install \\\n",
    "    apt-transport-https \\\n",
    "    ca-certificates \\\n",
    "    curl \\\n",
    "    gnupg \\\n",
    "    lsb-release\n",
    "\n",
    "!curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n",
    "!echo \\\n",
    "  \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n",
    "  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install docker-ce docker-ce-cli containerd.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDNbIBw8gH_r",
    "outputId": "a80fad91-d47e-44ad-e35b-f989635bed0d"
   },
   "outputs": [],
   "source": [
    "!sudo service docker stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-Wpo3NBfD5W",
    "outputId": "f00a0ecd-3197-4f57-dd7b-875c60a7c74d"
   },
   "outputs": [],
   "source": [
    "!sudo docker run hello-world\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yQVppTtfJl3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "miNB933xYklP",
    "wC-y4mZj8t10",
    "PflVuKGTHz1r",
    "uPpOJrSHH3gj",
    "4oMk-CFBa99A",
    "ICIm0YlCEnjY"
   ],
   "name": "t5-code-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
