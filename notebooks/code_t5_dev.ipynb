{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Egor.Spirin/JetBrains/code-t5\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import gin\n",
    "import seqio\n",
    "import t5\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from contextlib import contextmanager\n",
    "from tensorflow.compat.v1 import logging\n",
    "\n",
    "from code_t5.constants import NEWLINE\n",
    "from code_t5.tasks import register_dev_task"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Improve logging.\n",
    "@contextmanager\n",
    "def tf_verbosity_level(level):\n",
    "    log_level = logging.get_verbosity()\n",
    "    logging.set_verbosity(level)\n",
    "    yield\n",
    "    logging.set_verbosity(log_level)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def decode(vocab, s):\n",
    "    return vocab.decode(s.tolist()).replace(NEWLINE, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define properties"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "BASE_DIR = \"../data/mlp-8\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "VOCAB_PATH = os.path.join(DATA_DIR, \"dataset-dev\", \"dev.model\")\n",
    "\n",
    "MODEL_SIZE = \"arch-lm_v1-lm\" #@param[\"small\", \"base\", \"base-t5.1.1\", \"base_shared\", \"base_shared_1k\", \"base-top5k\", \"base-top5k\", \"lm_ifa_1k\", \"arch-lm_v1-lm\", \"large\", \"3B\", \"11B\"]\n",
    "MODEL_DIR = os.path.join(MODELS_DIR, MODEL_SIZE)\n",
    "CACHE_DIR = os.path.join(BASE_DIR, \"cache\")\n",
    "\n",
    "TRAIN_STEPS = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with gin.unlock_config():\n",
    "    gin.bind_parameter(\n",
    "        \"preprocessors.unsupervised.preprocessors\",\n",
    "        [\n",
    "            t5.data.preprocessors.select_random_chunk,\n",
    "            # t5.data.preprocessors.reduce_concat_tokens,\n",
    "            # t5.data.preprocessors.split_tokens_to_targets_length,\n",
    "            t5.data.preprocessors.split_tokens_to_inputs_length,\n",
    "            t5.data.preprocessors.denoise\n",
    "        ],\n",
    "    )\n",
    "    gin.bind_parameter(\"preprocessors.select_random_chunk.max_length\", 65536)\n",
    "    gin.bind_parameter(\"preprocessors.denoise.inputs_fn\", t5.data.preprocessors.drop_noise_tokens)\n",
    "    gin.bind_parameter(\"preprocessors.denoise.noise_density\", 0.5)\n",
    "    gin.bind_parameter(\"preprocessors.denoise.noise_mask_fn\", t5.data.preprocessors.random_prefix_noise_mask)\n",
    "    gin.bind_parameter(\"preprocessors.denoise.targets_fn\", t5.data.preprocessors.drop_nonnoise_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "vocab = seqio.SentencePieceVocabulary(VOCAB_PATH, t5.data.DEFAULT_EXTRA_IDS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering dev task...\n"
     ]
    },
    {
     "data": {
      "text/plain": "dict_keys(['dev'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqio.TaskRegistry.reset()\n",
    "register_dev_task(DATA_DIR, vocab)\n",
    "seqio.TaskRegistry.names()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 14:32:17.310409: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Egor.Spirin/miniconda3/envs/code-t5/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869: RandomDataset.__init__ (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.random(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Egor.Spirin/miniconda3/envs/code-t5/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869: RandomDataset.__init__ (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.random(...)`.\n"
     ]
    }
   ],
   "source": [
    "dev_task = seqio.TaskRegistry.get(\"dev\")\n",
    "dataset = dev_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 128}, use_cached=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "{'inputs': array([   14, 25217,  2702,    14, 25217,   877,    14,  2331,  3650,\n",
      "          14,  2331,  1403,    14, 25217,  3650,    14, 25217,  1403,\n",
      "         183,     3,    11,    10,    17,     6,    33,   553,    37,\n",
      "       18667,  8591,    85,  2685,   504,  1298,    38,   549,    37,\n",
      "        6917,  4231,    51,  5802,     1], dtype=int32), 'targets': array([25217,   360,   388,  3535, 18921,     4,     3,    11,    16,\n",
      "           4,   251,    30, 25217,  2685,  1276,    68,   276,   186,\n",
      "        1566,   183,    68,    70,   186, 25217,   208,  3291,  1175,\n",
      "          26,    15,     4,   249,     5,  1444,   256,    17,   320,\n",
      "        2376,  2276,     7,    31,     5,   560,    45,   103,     5,\n",
      "         131,     5,  9414,     5,   588,     5,  2421,    35,     3,\n",
      "          25,    72,     5,  2331,     5,  9414,     5,   588,     5,\n",
      "        2421,     7,    15,     8,   466,     5,   171,    13,    17,\n",
      "           6,    16,     4,   135,     4,   341,     7,     3,    11,\n",
      "         217,  2331,  2702,    14,  2331,   877,     1], dtype=int32)}\n",
      "Inputs: 41\n",
      "'\"vmss1\": \"vmss1\", \"vm2\": \"vm2\", \"vmss2\": \"vmss2\",}\n",
      "  )\n",
      "\n",
      "  # create a linux vm with identity but w/o a role assignment (--'\n",
      "Targets: 88\n",
      "'vmss has no assigned identities.\n",
      "   self.cmd(\"vmss identity remove -g {rg} -n {vmss3}\", checks=self.is_empty())\n",
      "\n",
      " @ResourceGroupPreparer(name_prefix=\"cli_test_msi_no_scope\")\n",
      " def test_vm_msi_no_scope(self, resource_group):\n",
      "\n",
      "  self.kwargs.update(\n",
      "   {\"vm1\": \"vm1\",'\n",
      "----\n",
      "\n",
      "----\n",
      "{'inputs': array([   16,     4,   135,    87,   416,   477,    46,     5,  1273,\n",
      "         112,     9,  2748,     5,  1273, 13354,     6,    12,  2748,\n",
      "           5,  1273,     4, 13959,  2018,    56,  1133,    56,    14,\n",
      "          46,  7382,   416,   477,    46,    22,    17,     6,    33,\n",
      "         903, 13763,     3,     6,    16,     4,   251,    30,  2331,\n",
      "        6527,    39,  1837, 13763,    68,   276,   186,  1566,   183,\n",
      "         247,  2331,    39,    31,   186,  2331,   183,    68,    70,\n",
      "         186,  1837,   183,   247,     1], dtype=int32), 'targets': array([  418,    30,   107,     7,   375,  5849,     4,   111, 16105,\n",
      "          23,    10,    18,  2870,     4,    55,     5,   301,     5,\n",
      "         357,     5,   527,    32,    17,     6,    33,    88,    19,\n",
      "         393,   477,    46,  5220,    60, 14778,    54,    23,   975,\n",
      "           5,   988,     3,     6,  2748,     5,  1273,     9,   229,\n",
      "          87,   375,  5849,  1592,   245, 16105,  1592,   416,   477,\n",
      "          46,  1592,  1273,   112,    17,     6,     1], dtype=int32)}\n",
      "Inputs: 68\n",
      "'self.kwargs[\"vhd_uri\"] = blob_uri[0 : blob_uri.rindex(\"/\") + 1] + \"d7.vhd\"\n",
      "\n",
      "  # now attach\n",
      "  self.cmd(\"vm unmanaged-disk attach -g {rg} --vm-name {vm} -n {disk} --'\n",
      "Targets: 61\n",
      "'check(\"length(storageProfile.dataDisks)\", 0)).get_output_in_json()\n",
      "\n",
      "  # get the vhd uri from VM's storage_profile\n",
      "  blob_uri = result[\"storageProfile\"][\"osDisk\"][\"vhd\"][\"uri\"]\n",
      "\n",
      " '\n",
      "----\n",
      "\n",
      "----\n",
      "{'inputs': array([ 39, 458,   1], dtype=int32), 'targets': array([  301,     4,  4522,    32,  1579,     4,   321,   256,     3,\n",
      "           6,    16,     4,   499,     7,   148,   551,   335,     5,\n",
      "         171,     5,   661,     8,    16,     4,   135,    87, 22347,\n",
      "       19062,     4,   249,   916,   148,     7,   312,     5,   301,\n",
      "          71,    17,   320,  2376,  2276,     7,    31,     5,   560,\n",
      "          45,   103,     5,   131,     5,  2331,     5,  2537,    18,\n",
      "        1161,    45, 10037,    35,     3,   320,  2005,  6350,     7,\n",
      "         298,     5,  6561,    26, 21985,  9436,     3,    25,    72,\n",
      "           5,  2331,     5,   235,     5,   589,     5,  2537,     5,\n",
      "       27873,     7,    15,     8,   466,     5,   171,     8,   466,\n",
      "           5,   171,     5,   661,    13,     3,     6,   142,    12,\n",
      "           3,    11,    16,     4,   251,    30,  2331,   553,    68,\n",
      "         276,   186,  1566,   183,    68,    70,  8591,   115,   247,\n",
      "         319,    39,   528,     6,   103,  4998,   247,   319,     1],\n",
      "      dtype=int32)}\n",
      "Inputs: 3\n",
      "'-password'\n",
      "Targets: 126\n",
      "'output.splitlines()[2].split())\n",
      "  self.assertTrue(set([resource_group_location, self.kwargs[\"zones\"]]).issubset(table_output))\n",
      "\n",
      " @ResourceGroupPreparer(name_prefix=\"cli_test_vm_zone\", location=\"westus\")\n",
      " @AllowLargeResponse(size_kb=99999)\n",
      " def test_vm_error_on_zone_unavailable(self, resource_group, resource_group_location):\n",
      "  try:\n",
      "   self.cmd(\"vm create -g {rg} -n vm1 --admin-username clitester --admin'\n",
      "----\n",
      "\n",
      "----\n",
      "{'inputs': array([  635,    47,    14, 20534,    18,    14,   431,    47,    14,\n",
      "        2259,    18,    14,  2259,     5,    82,    47,  4393,     5,\n",
      "        7581,     5,  1140,     1], dtype=int32), 'targets': array([23717, 27518,    18,  1175,    26,    15,     4,   418,    30,\n",
      "         797,  4280,    23,  2050,   950, 14341,    23,  2050,   104,\n",
      "          18,    77,   276,     5,   104,    71,    52,     6,  7606,\n",
      "          23,  3157,     7,  3157,    13,     6,    33,   715,    12,\n",
      "         716,    26,  1921,    39,  1740,    39,   701,    39,  3318,\n",
      "           3,   320,  2376,  2276,     7,    31,     5,   560,    45,\n",
      "         103,     5,   131,     5,  2331,     5,  6294,    35,     3,\n",
      "          25,    72,     5,  2331,     5,   158,     5,  5748,     5,\n",
      "        6294,     7,    15,     8,   466,     5,   171,     8,   466,\n",
      "           5,   171,     5,   661,    13,    17,     6,    16,     4,\n",
      "         135,     4,   341,  1147,   319,    47,    14, 15159,    18,\n",
      "          14,  2747,    47,    14, 10037,    18,    14,     1],\n",
      "      dtype=int32)}\n",
      "Inputs: 22\n",
      "'image\": \"UbuntuLTS\", \"auth\": \"ssh\", \"ssh_key\": TEST_SSH_KEY'\n",
      "Targets: 107\n",
      "'VMNIC\", checks=self.check(\"ipConfigurations[0].applicationSecurityGroups[0].id\", asg_id))\n",
      "\n",
      "\n",
      "class SecretsScenarioTest(ScenarioTest):  # pylint: disable=too-many-instance-attributes\n",
      " @ResourceGroupPreparer(name_prefix=\"cli_test_vm_secrets\")\n",
      " def test_vm_create_linux_secrets(self, resource_group, resource_group_location):\n",
      "\n",
      "  self.kwargs.update({\"admin\": \"ubuntu\", \"loc\": \"westus\", \"'\n",
      "----\n",
      "\n",
      "----\n",
      "{'inputs': array([   5,  560,   45,  103,    5,  131,    5, 2331,    5,  158,    5,\n",
      "          1], dtype=int32), 'targets': array([    6,    16,     4,   251,    30, 25217,   553,    68,   276,\n",
      "         186,  1566,   183,    68,    70,   186, 25217,   183,   247,\n",
      "         635,     6, 20534,   247,  3622,    39,  1690,  7239,   247,\n",
      "        3180,     6, 30595,   247, 14028, 31266,    39,  1499,  2646,\n",
      "        9667,   247,   114,    39,  3503,  6019,    18,  1175,  1144,\n",
      "          15,     4,   418,    30, 25217,     4,  2821,   198, 15573,\n",
      "        9915,  5849,     4,  3180,    18,    14, 30595,   167,    16,\n",
      "           4,   418,    30, 25217,     4,  2821,   198, 15573,  9915,\n",
      "        5849,     4, 14028, 31266,  7955,    18,    14,  1971,  9667,\n",
      "         167,    16,     4,   418,    30, 25217,     4,  2821,   198,\n",
      "       15573,  9915,  5849,     4,  3503,  5849,     4,   114, 10726,\n",
      "          18, 12324,   314,    52, 14778,  2640, 12360,   991,     7,\n",
      "        3157,    13,     3,   320,  2376,  2276,     7,    31,     1],\n",
      "      dtype=int32)}\n",
      "Inputs: 12\n",
      "'_prefix=\"cli_test_vm_create_'\n",
      "Targets: 117\n",
      "'self.cmd(\"vmss create -g {rg} -n {vmss} --image UbuntuLTS --lb-sku Standard --priority Low --eviction-policy Deallocate --max-billing=50\", checks=[self.check(\"vmss.virtualMachineProfile.priority\", \"Low\"), self.check(\"vmss.virtualMachineProfile.evictionPolicy\", \"Deallocate\"), self.check(\"vmss.virtualMachineProfile.billingProfile.maxPrice\", 50)])\n",
      "\n",
      "\n",
      "class VMCreateSpecialName(ScenarioTest):\n",
      " @ResourceGroupPreparer(name'\n",
      "----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 14:32:20.825357: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for ex in tfds.as_numpy(dataset.take(5)):\n",
    "    print(\"----\")\n",
    "    print(ex)\n",
    "    if \"inputs\" in ex:\n",
    "        print(f\"Inputs: {tf.size(ex['inputs'])}\\n'{decode(vocab, ex['inputs'])}'\")\n",
    "    print(f\"Targets: {tf.size(ex['targets'])}\\n'{decode(vocab, ex['targets'])}'\")\n",
    "    print(\"----\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}